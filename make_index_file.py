import time
import sys
import logging
import subprocess
import os
import shutil
import hashlib
from pathlib import Path
import click
import numpy as np
from astropy.io import fits
from astropy.table import Table
from astropy.table import join as table_join
from astropy.time import Time
from glob import glob


"""
ATTENTION RAJOUTER LES AEFF, EDISP ET PSF QUAND ELLES SERONT PRODUITES 
"""
obs_ids = [int(file[6:11]) for file in glob('run*.fits')]

class Location:
    """Directory and file locations"""
    OUT_DIR = Path('out')

    RUN_LIST_EXPORT = Path('runs.lis')

    # File and observation index files
    INDEX_FILE_TABLE = OUT_DIR / 'hdu-index.fits.gz'
    INDEX_OBS_TABLE = OUT_DIR / 'obs-index.fits.gz'

    # Background modeling
    BG_MODEL_DIR = OUT_DIR / 'background'
    BG_MODEL_GROUPING = BG_MODEL_DIR / 'background_grouping.ecsv'
    BG_MODEL_OFF_RUNS = BG_MODEL_DIR / 'background_runs.ecsv'
    BG_MODEL_OFF_RUNS_GROUPED = BG_MODEL_DIR / 'background_runs_grouped.ecsv'

class Observation:
    """Helper functions to compute file and folder names.
    """

    #filetypes = ['events', 'aeff', 'edisp', 'psf_3gauss']
    filetypes = ['events']

    def __init__(self, obs_id, hap_config=None, telpattern=None):
        self.obs_id = obs_id
        self.hap_config = hap_config
        self.telpattern = telpattern

    @property
    def obs_group(self):
        obs_id_min = self.obs_id - (self.obs_id % 200)
        obs_id_max = obs_id_min + 199
        return obs_id_min, obs_id_max

    @property
    def _obs_group_folder(self):
        return Path('run{:06d}-{:06d}'.format(self.obs_group[0], self.obs_group[1]))

    @property
    def _obs_folder(self):
        return Path('run{:06d}'.format(self.obs_id))

    def folder(self, step=None):
        """Create folder for a given step.
        """
        if step is None:
            return self._obs_group_folder / self._obs_folder
        else:
            return Path(step) / self._obs_group_folder / self._obs_folder

    def hap_filename(self, filetype):
        """Name of FITS file generated by HAP"""
        if filetype == 'events':
            return self.folder('events') / 'run_{:07d}_{}_eventlist.fits'.format(self.obs_id, self.hap_config)
            # return self.folder('events') / 'events_{:06d}.fits.gz'.format(self.obs_id)
        elif filetype == 'aeff':
            return self.folder('irfs') / 'aeff_{:06d}.fits.gz'.format(self.obs_id)
        elif filetype == 'edisp':
            return self.folder('irfs') / 'edisp_{:06d}.fits.gz'.format(self.obs_id)
        elif filetype == 'psf_3gauss':
            return self.folder('irfs') / 'psf_3gauss_{:06d}.fits.gz'.format(self.obs_id)
        else:
            raise ValueError('Invalid {} {}'.format(filetype))


    def out_filename(self, filetype, format='old', dir=Location.OUT_DIR):
        """Name of FITS file in out folder"""
        filename = self.filename(filetype=filetype, format=format)
        return Path(dir) / filename

    def filename(self, filetype, format='old'):
        if format == 'old':
            TAGS = dict(
                events='events',
                aeff='aeff_2d',
                edisp='edisp_2d',
                psf_3gauss='psf_3gauss',
                psf_king='psf_king',
                psf_table='psf_table',
                background='bkg_offruns',
            )
        elif format == 'new':
            TAGS = dict(
                events='events',
                aeff='aeff',
                edisp='edisp',
                psf_3gauss='psf_3gauss',
                psf_king='psf_king',
                psf_table='psf_table',
                background='background',
            )

        tag = TAGS[filetype]
        filename = '{}_{:06d}.fits.gz'.format(tag, self.obs_id)
        return self.folder() / filename
    
    def mkdir(self, step):
        """Make directory (parts=True, exists_ok=True)"""
        path = self.folder(step)
        if not path.exists():
            path.mkdir(parents=True)

        return path

    def check_out_files_exist(self):
        """Check if all out files exist"""
        for filetype in self.filetypes:
            filename = self.out_filename(filetype)
            if not filename.is_file():
                log.error('MISSING: {}'.format(filename))
                return False

        return True

class ListObservations:
    def __init__(self, runlist_file, config):
        self.observations = []
        runlist= np.loadtxt(runlist_file)
        obs_ids=runlist[:,0].astype(int)
        telcodes=runlist[:,1].astype(int)
        for obs_id, telcode in zip(obs_ids, telcodes):
            obs = Observation(obs_id, config, telcode)
            self.observations.append(obs)
        

def summary_info_events(filename):
    """Extract FITS header info from EVENTS files to dict"""
    # filename = self.out_filename('events')
    print('Reading {}'.format(filename))
    table = Table.read(str(filename), hdu='EVENTS')

    data = dict()

    # Copy over header info to the summary table
    data['RA_PNT'] = np.float32(table.meta['RA_PNT'])
    data['DEC_PNT'] = np.float32(table.meta['DEC_PNT'])
    #data['GLON_PNT'] = np.float32(table.meta['GLON_PNT'])
    #data['GLAT_PNT'] = np.float32(table.meta['GLAT_PNT'])
    data['ALT_PNT'] = np.float32(table.meta['ALT_PNT'])
    data['AZ_PNT'] = np.float32(table.meta['AZ_PNT'])
    data['ZEN_PNT'] = np.float32(90. - table.meta['ALT_PNT'])
    data['ONTIME'] = np.float32(table.meta['ONTIME'])
    data['LIVETIME'] = np.float32(table.meta['LIVETIME'])
    data['DEADC'] = np.float32(table.meta['DEADC'])

    MJDREFI = table.meta['MJDREFI']
    MJDREFF = table.meta['MJDREFF']
    MJDREF = MJDREFI + MJDREFF

    TSTART_MET = table.meta['TSTART'] / 3600. / 24.
    TSTOP_MET = table.meta['TSTOP'] / 3600. / 24.

    start_time = Time(MJDREF + TSTART_MET, scale='tt', format='mjd')
    stop_time = Time(MJDREF + TSTOP_MET, scale='tt', format='mjd')

    data['TSTART'] = np.float32(start_time.utc.mjd)
    data['TSTOP'] = np.float32(stop_time.utc.mjd)
    data['TSTART_STR'] = str(start_time.utc.iso[:-4])
    data['TSTOP_STR'] = str(stop_time.utc.iso[:-4])

    data['N_TELS'] = table.meta['N_TELS']
    data['TELLIST'] = table.meta['TELLIST']
    data['OBJECT'] = table.meta['OBJECT']
    data['RA_OBJ'] = np.float32(table.meta['RA_OBJ'])
    data['DEC_OBJ'] = np.float32(table.meta['DEC_OBJ'])

    # data['OBS_MODE'] = table.meta['OBS_MODE']

    try:
        data['MUONEFF'] = np.float32(table.meta['MUONEFF'])
    except KeyError:
        data['MUONEFF'] = np.float32(-1)

    # Calculate some summary statistics for important event columns
    data['EVENT_COUNT'] = len(table)
    data['EVENT_TIME_MIN'] = table['TIME'].min()
    data['EVENT_TIME_MAX'] = table['TIME'].max()
    data['EVENT_ENERGY_MEDIAN'] = np.float32(np.median(table['ENERGY']))
    data['EVENT_RA_MEDIAN'] = np.float32(np.median(table['RA']))
    data['EVENT_DEC_MEDIAN'] = np.float32(np.median(table['DEC']))

    return data


def summary_info_aeff(filename):
    """Extract FITS header info from AEFF files to dict"""
    # filename = self.out_filename('aeff')
    print('Reading {}'.format(filename))
    table = Table.read(str(filename), hdu='AEFF_2D')

    data = dict()

    # Copy over header info to the summary table
    data['LO_THRES'] = table.meta['LO_THRES']
    data['HI_THRES'] = table.meta['HI_THRES']

    # Summary stats on IRF file content
    data['EFFAREA_MAX'] = table['EFFAREA'].max()
    data['EFFAREA_RECO_MAX'] = table['EFFAREA_RECO'].max()

    return data




def obs_table(list_observations, indir, informat, outfile):
    """Create obs-index.fits.gz file.
    """
    print('Creating observations summary table ...')
    # We gather all infos in a list of dicts and write this
    # as a FITS table at the end.
    rows = []
    for obs in list_observations.observations:
        data = dict()
        data['OBS_ID'] = obs.obs_id
        events_filename = Path(indir) / obs.filename('events', format=informat)
        if events_filename.exists():
            events_info = summary_info_events(events_filename)
            data.update(events_info)
        else:
            print('File not found: {}'.format(events_filename))

        aeff_filename = Path(indir) / obs.filename('aeff', format=informat)
        if aeff_filename.exists():
            aeff_info = summary_info_aeff(aeff_filename)
            data.update(aeff_info)
            # check that thresholds are meaningful in the effective area table
            if aeff_info['HI_THRES'] <= aeff_info['LO_THRES']:
                print('HI_THRES < LO_THRES for aeff : {}'.format(obs.obs_id))
                data['QUALITY'] = DataQuality.bad['id']

        else:
            print('File not found: {}'.format(aeff_filename))

        # check that the energy column is filled
        if events_info['EVENT_ENERGY_MEDIAN'] <= 0:
            print('EVENT_ENERGY_MEDIAN <= 0 : {}'.format(obs.obs_id))
            data['QUALITY'] = DataQuality.bad['id']

        
        # TODO add more checks?

        # This currently only works if the dir is called 'out':
        # if not Observation(obs.obs_id).check_out_files_exist():
        #     print('Missing files: {}'.format(obs.obs_id))
        #     data['QUALITY'] = DataQuality.bad['id']

        rows.append(data)
    table = Table(rows=rows)

    table.meta['MJDREFI'] = 51544
    table.meta['MJDREFF'] = 0.5
    table['ZEN_PNT'].unit= "deg"
    table['RA_PNT'].unit= "deg"
    table['DEC_PNT'].unit= "deg" 
    table['ALT_PNT'].unit= "deg"
    table['AZ_PNT'].unit= "deg"
    
    print('Writing {}'.format(outfile))
    table.write(str(outfile), overwrite= True)
    # add hdu name - is there a better way to implement this?
    # (found no direct arg in table.write function)
    hdulist = fits.open(str(outfile), mode='update')
    hdulist[1].name = 'OBS_INDEX'
    hdulist.close()



def file_table(list_observations, indir, informat, outfile):
    """Create hdu-index.fits.gz file.

    \b
    Parameters
    ----------
    informat : {'new', 'old'}
        File naming format
    """
    print('Creating file summary table ...')

    # We gather all infos in a list of dicts and write this
    # as a FITS table at the end.
    # for documentation see http://gamma-astro-data-formats.readthedocs.org/en/latest/data_storage/hdu_index/index.html

    HDU_CLASS_TAGS = dict(
        events='events',
        aeff='aeff_2d',
        edisp='edisp_2d',
        psf_3gauss='psf_3gauss',
        psf_king='psf_king',
        psf_table='psf_table',
        gti='gti'
    )

    rows = []
    for obs in list_observations.observations:

        #for filetype in ['events', 'aeff', 'edisp', 'psf_3gauss']:
        for filetype in ['events']:

            filename = obs.out_filename(filetype, format=informat, dir=indir)

            if filename.is_file():
                print('Processing {}'.format(filename))

                data = dict()

                # OBS_ID
                data['OBS_ID'] = obs.obs_id

                # HDU_TYPE
                if filetype in ('psf_3gauss'):
                    data['HDU_TYPE'] = 'psf'
                else:
                    data['HDU_TYPE'] = str(filetype)

                # HDU_CLASS
                data['HDU_CLASS'] = HDU_CLASS_TAGS[filetype]

                # FILE_DIR (relative path)
                data['FILE_DIR'] = str(os.path.relpath(str(obs.out_filename(filetype).parent), str(Path(outfile).parent)))

                # FILE_NAME
                data['FILE_NAME'] = str(obs.filename(filetype, format=informat).parts[-1])

                # HDU-INFOS
                hdu_list = fits.open(str(filename))
                hdu = hdu_list[1]
                header = hdu.header
                data['HDU_NAME'] = hdu.name

                # FILE-INFOS
                stat = filename.stat()
                data['SIZE'] = stat.st_size
                data['MTIME'] = stat.st_mtime
                data['MD5'] = hashlib.md5(filename.open('rb').read()).hexdigest()

                # if 'HDUCLAS2' in header:
                #    data['HDUCLASS'] = header['HDUCLAS2']
                # else:
                #    data['HDUCLASS'] = 'EVENTS'

                # if its the events-file, use a second dict for the gti-hdu
                if filetype == 'events':
                    data_gti = dict()
                    data_gti['OBS_ID'] = obs.obs_id
                    data_gti['HDU_TYPE'] = 'gti'
                    data_gti['HDU_CLASS'] = 'gti'
                    data_gti['FILE_DIR'] = data['FILE_DIR']
                    data_gti['FILE_NAME'] = data['FILE_NAME']
                    data_gti['HDU_NAME'] = hdu_list[2].name
                    data_gti['SIZE'] = data['SIZE']
                    data_gti['MTIME'] = data['MTIME']
                    data_gti['MD5'] = data['MD5']

                    rows.append(data_gti)

                rows.append(data)
                hdu_list.close()

            else:
                print('File not found: {}'.format(filename))

    names = [
        'OBS_ID', 'HDU_TYPE', 'HDU_CLASS',
        'FILE_DIR', 'FILE_NAME', 'HDU_NAME',
        'SIZE', 'MTIME', 'MD5'
    ]
    table = Table(rows=rows, names=names)

    print('Writing {}'.format(outfile))
    table.write(str(outfile), overwrite=True)
    # add hdu name
    hdulist = fits.open(str(outfile), mode='update')
    hdulist[1].name = 'HDU_INDEX'
    hdulist.close()

def make_index_file():
    observation_list = ListObservations("runlist.txt" ,"std_north_1b")
    obs_table(observation_list, "/Users/jouvin/Desktop/these/FITS_DATA/HAP-FR/Prod15_4_stereo/ash_south", "old", "obs-index.fits.gz" )
    file_table(observation_list, "/Users/jouvin/Desktop/these/FITS_DATA/HAP-FR/Prod15_4_stereo/ash_south", "old", "hdu-index.fits.gz" )
if __name__ == '__main__':
    make_index_file()
    
